<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vojtech Kejzlar, Ph.D.</title>
    <link>http://www.kejzlar.com/</link>
    <description>Recent content on Vojtech Kejzlar, Ph.D.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 10 Oct 2023 00:00:00 +0000</lastBuildDate><atom:link href="http://www.kejzlar.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to: logistic regression pipeline in Python</title>
      <link>http://www.kejzlar.com/posts/logistic-python/</link>
      <pubDate>Tue, 10 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>http://www.kejzlar.com/posts/logistic-python/</guid>
      <description>Table of ContentsLink to headingIntroduction Logistic regression overview Exploratory data analysis and feature engineering Model fitting and performance metrics Feature selection Feature importance I recently stumbled upon a nice Superstore Marketing Campaign Dataset during my weekly (as one does :) ) browsing sessions through Kaggle. The Kaggle data card has great motivation build around the dataset that I am pasting here:
Context: A superstore is planning for the year-end sale.</description>
    </item>
    
    <item>
      <title>Variational Inference - scalable UQ for probabilistic models</title>
      <link>http://www.kejzlar.com/posts/vi-tutorial/</link>
      <pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>http://www.kejzlar.com/posts/vi-tutorial/</guid>
      <description>Table of ContentsLink to headingIntroduction Idea behind variational inference Variational families ELBO optimization Estimating the average number of active players in an mmorpg Document clustering with LDA Probabilistic models like logistic regression, Bayesian classification, neural networks, and models for natural language processing, are increasingly more present in the world of data science and machine learning. If you want to use these models for reliable infernce (such as prediction), you should always do your best to carry out some type of uncertainty quantification (UQ) which will give you a good idea about the limits of models you used.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://www.kejzlar.com/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.kejzlar.com/about/</guid>
      <description>Hi, I am Vojtech (Vojta) Kejzlar. I am a data scientist, an academic, and a science educator. My work focuses on Bayesian data analysis, predictive modeling, and uncertainty quantification in the context of machine learning. I build statistical and machine learning tools to solve problems in physical sciences and create innovative resources for data science literacy. I am currently an Assistant Professor of Statistics in the Department of Mathematics and Statistics at Skidmore College in Saratoga Springs, New York.</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>http://www.kejzlar.com/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.kejzlar.com/projects/</guid>
      <description>Here are projects that I have been working on during the past couple of years. They are a mix of Bayesian data analysis, machine learning modeling, and data science education. Take a look at the list of my publications and my GitHub to see the fruits of this labor.
Bayesian Mining of Nuclear Mass DataLink to headingThe mass, or binding energy, is the basic property of the atomic nucleus.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>http://www.kejzlar.com/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.kejzlar.com/publications/</guid>
      <description>Vojtech Kejzlar, Leo Neufcourt, Witold Nazarewicz (2023). Local Bayesian Dirichlet Mixing of Imperfect Models. Scientific Reports. arXiv
Vojtech Kejzlar, Tapabrata Maiti (2023). Variational Inference With Vine Copulas: an Efficient Approach for Bayesian Computer Model Calibration. Statistics and Computing. arXiv
Vojtech Kejzlar, Jingchen Hu (2023). Introducing Variational Inference in Statistics and Data Science Curriculum. The American Statistician. arXiv
Vojtech Kejzlar, Shrijita Bhattacharya, Mookyong Son, Tapabrata Maiti (2022). Black Box Variational Bayesian Model Averaging.</description>
    </item>
    
  </channel>
</rss>
